{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"indoNLP indoNLP adalah library python sederhana tanpa dependency tambahan yang bertujuan untuk memudahkan proyek NLP anda. Installasi indoNLP dapat diinstall dengan mudah dengan menggunakan pip : $ pip install indoNLP","title":"indoNLP"},{"location":"#indonlp","text":"indoNLP adalah library python sederhana tanpa dependency tambahan yang bertujuan untuk memudahkan proyek NLP anda.","title":"indoNLP"},{"location":"#installasi","text":"indoNLP dapat diinstall dengan mudah dengan menggunakan pip : $ pip install indoNLP","title":"Installasi"},{"location":"quickstart/","text":"Quick Start Mengakses Indonesian NLP Open Dataset Mengakses Indonesian NLP Open Dataset dengan cepat dan mudah. from indoNLP.dataset import Dataset handler = Dataset ( \"id-multi-label-hate-speech-and-abusive-language-detection\" ) data = handler . read () Jika data bersifat simetrik maka data dapat ditabelisasi menggunakan pandas.DataFrame import pandas as pd df = pd . DataFrame ( data ) Preprocessing Data Teks Menerjemahkan emoji dan mengganti kata gaul ( slang words ) from indoNLP.preprocessing import emoji_to_words , replace_slang , pipeline pipe = pipeline ([ emoji_to_words , replace_slang ]) pipe ( \"library yg membara \ud83d\udd25\" ) # \"library yang membara !api!\"","title":"Quick Start"},{"location":"quickstart/#quick-start","text":"","title":"Quick Start"},{"location":"quickstart/#mengakses-indonesian-nlp-open-dataset","text":"Mengakses Indonesian NLP Open Dataset dengan cepat dan mudah. from indoNLP.dataset import Dataset handler = Dataset ( \"id-multi-label-hate-speech-and-abusive-language-detection\" ) data = handler . read () Jika data bersifat simetrik maka data dapat ditabelisasi menggunakan pandas.DataFrame import pandas as pd df = pd . DataFrame ( data )","title":"Mengakses Indonesian NLP Open Dataset"},{"location":"quickstart/#preprocessing-data-teks","text":"Menerjemahkan emoji dan mengganti kata gaul ( slang words ) from indoNLP.preprocessing import emoji_to_words , replace_slang , pipeline pipe = pipeline ([ emoji_to_words , replace_slang ]) pipe ( \"library yg membara \ud83d\udd25\" ) # \"library yang membara !api!\"","title":"Preprocessing Data Teks"},{"location":"api/","text":"Kode Referensi indoNLP memiliki beberapa modul yang dapat digunakan yaitu: dataset preprocessing","title":"Kode Referensi"},{"location":"api/#kode-referensi","text":"indoNLP memiliki beberapa modul yang dapat digunakan yaitu: dataset preprocessing","title":"Kode Referensi"},{"location":"api/dataset/","text":"indoNLP.dataset indoNLP.dataset adalah modul yang bertujuan untuk memudahkan mengakses open dataset dalam bidang NLP untuk Bahasa Indonesia Dataset ( name , dataset_dir = None , auto_download = True ) Handler untuk dataset yang disupport indoNLP, berfungsi untuk mendownload, mengekstract, dan membaca data. Parameters: Name Type Description Default name str Nama dataset yang disupport indoNLP. required dataset_dir str indoNLP dataset download direktori. None auto_download bool Auto download dataset ketika kelas di inisiasi, jika dataset telah didownload sebelumnya maka proses download akan dilewati secara otomatis. True Attributes: Name Type Description dataset_name str Nama dataset yang disupport indoNLP. dataset_config Dict [ str , Any ] Konfigurasi dataset. file DatasetDirectoryHandler indoNLP dataset download direktori handler. downloader DataDownloader indoNLP dataset downloader. Examples: Download dan Loading dataset yang disupport. >>> data_handler = indoNLP . dataset . Dataset ( \"twitter-puisi\" ) >>> data_handler . read () get_info () Mendapatkan informasi dari dataset Informasi menghasilkan output yang sama dengan fungsi get_supported_dataset_info read ( get = 'all' ) Membaca file yang terdapat dalam dataset dan meloadnya kedalam memori. Jika data yang terdapat dalam file adalah simetric maka data dapat diload dengan menggunakan pandas.DataFrame . Parameters: Name Type Description Default get Union [ str , Tuple [ str ]] Nama file di dalam dataset untuk dibaca dan diload kedalam memori, jika \"all\" diset maka akan dibaca semua file yang ada di dalam dataset. 'all' Returns: Type Description Union [ Any , Tuple [ Any ]] Data dari file yang telah di read. Jika file yang dibaca berjumlah lebih dari 2 maka Union [ Any , Tuple [ Any ]] akan mengembalikan dalam bentuk Tuple sesuai dengan urutan nama file yang Union [ Any , Tuple [ Any ]] dispesifikasikan pada parameter get , jika \"all\" yang diberikan maka urutan data dari Union [ Any , Tuple [ Any ]] file akan sesuai dengan urutan yang ada pada metode get_info() . Examples: Membaca dan loading sebuah file >>> data_handler = indoNLP . dataset . Dataset ( \"twitter-puisi\" ) >>> puisi = data_handler . read () twitter-puisi twitter-puisi dataset hanya memiliki 1 file didalamnya Read multiple files >>> data_handler = indoNLP . dataset . Dataset ( \"asian-language-treebank-parallel-corpus\" ) >>> data_id , data_ja = data_handler . read ( get = ( \"id\" , \"ja\" )) asian-language-treebank-parallel-corpus asian-language-treebank-parallel-corpus dataset memiliki banyak file didalamnya get_supported_dataset_info ( name ) Mendapatkan informasi terkait salah satu dataset yang disupport indoNLP. Parameters: Name Type Description Default name str Nama dataset yang dipilih. required Raises: Type Description KeyError Dataset tidak ditemukan (tidak disupport indoNLP). get_supported_dataset_list ( filter_tags = None ) Mendapatkan list dataset yang disupport oleh indoNLP Parameters: Name Type Description Default filter_tags Union [ str , Sequence [ str ]] Filter dataset berdasarkan tags. None Informasi Untuk lebih lengkapnya list dataset yang disupport indoNLP dapat dilihat pada Supported Dataset DataDownloader ( name , files , download_dir = None ) Dataset downloader, berfungsi untuk mendownload dan mengekstrak data secara langsung. Dapat digunakan untuk mendownload data yang tidak disupport oleh indoNLP dengan beberapa konfigurasi tambahan. Parameters: Name Type Description Default name str Nama dataset. required files List [ Dict [ str , str ]] List dari file - file yang terdapat pada dataset. Dictionary data harus mengandung elemen \"filename\" (str), \"url\" (str), dan \"extract\" (bool) agar proses dapat berjalan dengan baik. required download_dir Union [ str , DatasetDirectoryHandler ] indoNLP dataset download direktori handler. None Attributes: Name Type Description dataset_name str Nama dataset. dataset_files List [ Dict [ str , str ]] List dari file - file yang terdapat pada dataset. file DatasetDirectoryHandler indoNLP dataset download direktori handler. dataset_dir str Direktori tempat dataset didownload. Examples: Mendownload data yang tidak disupport oleh indoNLP . >>> downloader = indoNLP . dataset . downloader . DataDownloader ( ... \"msa-all-tab\" , ... files = [ ... { ... \"filename\" : \"Bahasa-Wordnet-master.zip\" , ... \"url\" : \"https://codeload.github.com/limaginaire/Bahasa-Wordnet/zip/refs/heads/master\" , ... \"is_large\" : True , ... \"extract\" : True , ... } ... ], ... download_dir = \"temp\" , ...) >>> downloader . download () check () Melakukan pengecekan apakah dataset masih tersedia pada url yang diberikan. Returns: Type Description List [ Dict [ str , Union [ str , int ]]] List status ketersediaan dari file - file di dataset. (status code) Examples: Mengecek ketersediaan dataset yang tidak disupport indoNLP di internet. >>> downloader = indoNLP . dataset . downloader . DataDownloader ( ... \"msa-all-tab\" , ... files = [ ... { ... \"filename\" : \"Bahasa-Wordnet-master.zip\" , ... \"url\" : \"https://codeload.github.com/limaginaire/Bahasa-Wordnet/zip/refs/heads/master\" , ... \"is_large\" : True , ... \"extract\" : True , ... } ... ], ... download_dir = \"temp\" , ...) >>> downloader . check () [{\"filename\": \"Bahasa-Wordnet-master.zip\", \"available\": True, \"status\": 200}] download () Mendownload dataset, proses ini dilakukan dengan mengiterasi setiap file yang ada di dalam dataset untuk di download. Proses ini termasuk dengan proses ekstraksi ketika file telah selesai di download dan extract=True terdapat pada dataset dictionary di parameter files Note Proses ini hanya akan berjalan jika file - file dalam dataset belum pernah didownload sebelumnya. csv_reader ( path , fd_kwargs = {}, reader_kwargs = {}) csv file reader dimana data yang dikembalikan dapat langsung di pass kedalam pandas.DataFrame untuk melihat data dalam versi tablenya. Parameters: Name Type Description Default path str Path ke file csv. required fd_kwargs Dict [ str , Any ] File opener kwargs. {} reader_kwargs Dict [ str , Any ] Reader kwargs. {} Returns: Type Description Dict [ str , List [ Any ]] Data yang siap digunakan. jsonl_table_reader ( path , fd_kwargs = {}, reader_kwargs = {}) Symmetric jsonl file reader dimana data yang dikembalikan dapat langsung di pass kedalam pandas.DataFrame untuk melihat data dalam versi tablenya. Parameters: Name Type Description Default path str Path ke jsonl file. required fd_kwargs Dict [ str , Any ] File opener kwargs. {} reader_kwargs Dict [ str , Any ] Reader kwargs. {} Returns: Type Description Dict [ str , List [ Any ]] Data yang siap digunakan. txt_table_reader ( path , header = True , delimiter = ' \\t ' , fd_kwargs = {}) txt file reader dimana data yang dikembalikan dapat langsung di pass kedalam pandas.DataFrame untuk melihat data dalam versi tablenya. Parameters: Name Type Description Default path str Path ke file txt. required header bool Apakah data memiliki header, jika True diberikan maka baris pertama dari data akan dianggap sebagai header. True delimiter str Delimiter (pemisah). '\\t' fd_kwargs Dict [ str , Any ] File opener kwargs. {} Returns: Type Description Dict [ str , List [ Any ]] Data yang siap digunakan. DatasetDirectoryHandler ( download_dir = None ) Dataset directory handler, berfungsi untuk menghandle indoNLP main direktori untuk dataset. Secara otomatis data akan ditempatkan pada ~/.cache/indoNLP. Parameters: Name Type Description Default download_dir str Path ke main direktori untuk dataset. Jika None diset maka main direktori akan diarakan ke default yaitu ~/.cache/indoNLP. None Attributes: Name Type Description download_dir str Direktori indoNLP downloaded dataset. config_path str Konfigurasi file path. handler_config Dict [ str , Dict [ str , Any ]] indoNLP dataset configuration.","title":"Dataset"},{"location":"api/dataset/#indonlpdataset","text":"indoNLP.dataset adalah modul yang bertujuan untuk memudahkan mengakses open dataset dalam bidang NLP untuk Bahasa Indonesia","title":"indoNLP.dataset"},{"location":"api/dataset/#indoNLP.dataset.Dataset","text":"Handler untuk dataset yang disupport indoNLP, berfungsi untuk mendownload, mengekstract, dan membaca data. Parameters: Name Type Description Default name str Nama dataset yang disupport indoNLP. required dataset_dir str indoNLP dataset download direktori. None auto_download bool Auto download dataset ketika kelas di inisiasi, jika dataset telah didownload sebelumnya maka proses download akan dilewati secara otomatis. True Attributes: Name Type Description dataset_name str Nama dataset yang disupport indoNLP. dataset_config Dict [ str , Any ] Konfigurasi dataset. file DatasetDirectoryHandler indoNLP dataset download direktori handler. downloader DataDownloader indoNLP dataset downloader. Examples: Download dan Loading dataset yang disupport. >>> data_handler = indoNLP . dataset . Dataset ( \"twitter-puisi\" ) >>> data_handler . read ()","title":"Dataset"},{"location":"api/dataset/#indoNLP.dataset.Dataset.get_info","text":"Mendapatkan informasi dari dataset Informasi menghasilkan output yang sama dengan fungsi get_supported_dataset_info","title":"get_info()"},{"location":"api/dataset/#indoNLP.dataset.Dataset.read","text":"Membaca file yang terdapat dalam dataset dan meloadnya kedalam memori. Jika data yang terdapat dalam file adalah simetric maka data dapat diload dengan menggunakan pandas.DataFrame . Parameters: Name Type Description Default get Union [ str , Tuple [ str ]] Nama file di dalam dataset untuk dibaca dan diload kedalam memori, jika \"all\" diset maka akan dibaca semua file yang ada di dalam dataset. 'all' Returns: Type Description Union [ Any , Tuple [ Any ]] Data dari file yang telah di read. Jika file yang dibaca berjumlah lebih dari 2 maka Union [ Any , Tuple [ Any ]] akan mengembalikan dalam bentuk Tuple sesuai dengan urutan nama file yang Union [ Any , Tuple [ Any ]] dispesifikasikan pada parameter get , jika \"all\" yang diberikan maka urutan data dari Union [ Any , Tuple [ Any ]] file akan sesuai dengan urutan yang ada pada metode get_info() . Examples: Membaca dan loading sebuah file >>> data_handler = indoNLP . dataset . Dataset ( \"twitter-puisi\" ) >>> puisi = data_handler . read () twitter-puisi twitter-puisi dataset hanya memiliki 1 file didalamnya Read multiple files >>> data_handler = indoNLP . dataset . Dataset ( \"asian-language-treebank-parallel-corpus\" ) >>> data_id , data_ja = data_handler . read ( get = ( \"id\" , \"ja\" )) asian-language-treebank-parallel-corpus asian-language-treebank-parallel-corpus dataset memiliki banyak file didalamnya","title":"read()"},{"location":"api/dataset/#indoNLP.dataset.get_supported_dataset_info","text":"Mendapatkan informasi terkait salah satu dataset yang disupport indoNLP. Parameters: Name Type Description Default name str Nama dataset yang dipilih. required Raises: Type Description KeyError Dataset tidak ditemukan (tidak disupport indoNLP).","title":"get_supported_dataset_info()"},{"location":"api/dataset/#indoNLP.dataset.get_supported_dataset_list","text":"Mendapatkan list dataset yang disupport oleh indoNLP Parameters: Name Type Description Default filter_tags Union [ str , Sequence [ str ]] Filter dataset berdasarkan tags. None Informasi Untuk lebih lengkapnya list dataset yang disupport indoNLP dapat dilihat pada Supported Dataset","title":"get_supported_dataset_list()"},{"location":"api/dataset/#indoNLP.dataset.downloader.DataDownloader","text":"Dataset downloader, berfungsi untuk mendownload dan mengekstrak data secara langsung. Dapat digunakan untuk mendownload data yang tidak disupport oleh indoNLP dengan beberapa konfigurasi tambahan. Parameters: Name Type Description Default name str Nama dataset. required files List [ Dict [ str , str ]] List dari file - file yang terdapat pada dataset. Dictionary data harus mengandung elemen \"filename\" (str), \"url\" (str), dan \"extract\" (bool) agar proses dapat berjalan dengan baik. required download_dir Union [ str , DatasetDirectoryHandler ] indoNLP dataset download direktori handler. None Attributes: Name Type Description dataset_name str Nama dataset. dataset_files List [ Dict [ str , str ]] List dari file - file yang terdapat pada dataset. file DatasetDirectoryHandler indoNLP dataset download direktori handler. dataset_dir str Direktori tempat dataset didownload. Examples: Mendownload data yang tidak disupport oleh indoNLP . >>> downloader = indoNLP . dataset . downloader . DataDownloader ( ... \"msa-all-tab\" , ... files = [ ... { ... \"filename\" : \"Bahasa-Wordnet-master.zip\" , ... \"url\" : \"https://codeload.github.com/limaginaire/Bahasa-Wordnet/zip/refs/heads/master\" , ... \"is_large\" : True , ... \"extract\" : True , ... } ... ], ... download_dir = \"temp\" , ...) >>> downloader . download ()","title":"DataDownloader"},{"location":"api/dataset/#indoNLP.dataset.downloader.DataDownloader.check","text":"Melakukan pengecekan apakah dataset masih tersedia pada url yang diberikan. Returns: Type Description List [ Dict [ str , Union [ str , int ]]] List status ketersediaan dari file - file di dataset. (status code) Examples: Mengecek ketersediaan dataset yang tidak disupport indoNLP di internet. >>> downloader = indoNLP . dataset . downloader . DataDownloader ( ... \"msa-all-tab\" , ... files = [ ... { ... \"filename\" : \"Bahasa-Wordnet-master.zip\" , ... \"url\" : \"https://codeload.github.com/limaginaire/Bahasa-Wordnet/zip/refs/heads/master\" , ... \"is_large\" : True , ... \"extract\" : True , ... } ... ], ... download_dir = \"temp\" , ...) >>> downloader . check () [{\"filename\": \"Bahasa-Wordnet-master.zip\", \"available\": True, \"status\": 200}]","title":"check()"},{"location":"api/dataset/#indoNLP.dataset.downloader.DataDownloader.download","text":"Mendownload dataset, proses ini dilakukan dengan mengiterasi setiap file yang ada di dalam dataset untuk di download. Proses ini termasuk dengan proses ekstraksi ketika file telah selesai di download dan extract=True terdapat pada dataset dictionary di parameter files Note Proses ini hanya akan berjalan jika file - file dalam dataset belum pernah didownload sebelumnya.","title":"download()"},{"location":"api/dataset/#indoNLP.dataset.reader.csv_reader","text":"csv file reader dimana data yang dikembalikan dapat langsung di pass kedalam pandas.DataFrame untuk melihat data dalam versi tablenya. Parameters: Name Type Description Default path str Path ke file csv. required fd_kwargs Dict [ str , Any ] File opener kwargs. {} reader_kwargs Dict [ str , Any ] Reader kwargs. {} Returns: Type Description Dict [ str , List [ Any ]] Data yang siap digunakan.","title":"csv_reader()"},{"location":"api/dataset/#indoNLP.dataset.reader.jsonl_table_reader","text":"Symmetric jsonl file reader dimana data yang dikembalikan dapat langsung di pass kedalam pandas.DataFrame untuk melihat data dalam versi tablenya. Parameters: Name Type Description Default path str Path ke jsonl file. required fd_kwargs Dict [ str , Any ] File opener kwargs. {} reader_kwargs Dict [ str , Any ] Reader kwargs. {} Returns: Type Description Dict [ str , List [ Any ]] Data yang siap digunakan.","title":"jsonl_table_reader()"},{"location":"api/dataset/#indoNLP.dataset.reader.txt_table_reader","text":"txt file reader dimana data yang dikembalikan dapat langsung di pass kedalam pandas.DataFrame untuk melihat data dalam versi tablenya. Parameters: Name Type Description Default path str Path ke file txt. required header bool Apakah data memiliki header, jika True diberikan maka baris pertama dari data akan dianggap sebagai header. True delimiter str Delimiter (pemisah). '\\t' fd_kwargs Dict [ str , Any ] File opener kwargs. {} Returns: Type Description Dict [ str , List [ Any ]] Data yang siap digunakan.","title":"txt_table_reader()"},{"location":"api/dataset/#indoNLP.dataset.utils.DatasetDirectoryHandler","text":"Dataset directory handler, berfungsi untuk menghandle indoNLP main direktori untuk dataset. Secara otomatis data akan ditempatkan pada ~/.cache/indoNLP. Parameters: Name Type Description Default download_dir str Path ke main direktori untuk dataset. Jika None diset maka main direktori akan diarakan ke default yaitu ~/.cache/indoNLP. None Attributes: Name Type Description download_dir str Direktori indoNLP downloaded dataset. config_path str Konfigurasi file path. handler_config Dict [ str , Dict [ str , Any ]] indoNLP dataset configuration.","title":"DatasetDirectoryHandler"},{"location":"api/dataset/sup-dataset/","text":"Supported Dataset Berikut adalah daftar dataset yang disupport oleh indoNLP . Perhatian Disupport disini dimaksudkan sebagai dataset yang dapat digunakan secara langsung tanpa konfigurasi tambahan oleh indoNLP . indoNLP tidak memiliki hak cipta apapun terkait dataset yang ada di daftar! Name Description Author Year Homepage Tags twitter-puisi Loosely filtered poem from various user on Twitter unknown unknown twitter-puisi unlabeled id-multi-label-hate-speech-and-abusive-language-detection Dataset for multi-label hate speech and abusive language detection in the Indonesian Twitter Muhammad Okky Ibrohim and Indra Budi 2019 id-multi-label-hate-speech-and-abusive-language-detection labeled, hate speech, abusive language detection, multi-label, twitter id-abusive-language-detection Dataset for abusive language detection in the Indonesian language Muhammad Okky Ibrohim and Indra Budi 2018 id-abusive-language-detection labeled, abusive language detection asian-language-treebank-parallel-corpus The ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT, The process of building ALT began with sampling about 20,000 sentences from English Wikinews, and then these sentences were translated into the other languages. Muhammad Okky Ibrohim and Indra Budi 2016 asian-language-treebank-parallel-corpus machine translation","title":"Supported Dataset"},{"location":"api/dataset/sup-dataset/#supported-dataset","text":"Berikut adalah daftar dataset yang disupport oleh indoNLP . Perhatian Disupport disini dimaksudkan sebagai dataset yang dapat digunakan secara langsung tanpa konfigurasi tambahan oleh indoNLP . indoNLP tidak memiliki hak cipta apapun terkait dataset yang ada di daftar! Name Description Author Year Homepage Tags twitter-puisi Loosely filtered poem from various user on Twitter unknown unknown twitter-puisi unlabeled id-multi-label-hate-speech-and-abusive-language-detection Dataset for multi-label hate speech and abusive language detection in the Indonesian Twitter Muhammad Okky Ibrohim and Indra Budi 2019 id-multi-label-hate-speech-and-abusive-language-detection labeled, hate speech, abusive language detection, multi-label, twitter id-abusive-language-detection Dataset for abusive language detection in the Indonesian language Muhammad Okky Ibrohim and Indra Budi 2018 id-abusive-language-detection labeled, abusive language detection asian-language-treebank-parallel-corpus The ALT project aims to advance the state-of-the-art Asian natural language processing (NLP) techniques through the open collaboration for developing and using ALT, The process of building ALT began with sampling about 20,000 sentences from English Wikinews, and then these sentences were translated into the other languages. Muhammad Okky Ibrohim and Indra Budi 2016 asian-language-treebank-parallel-corpus machine translation","title":"Supported Dataset"},{"location":"api/preprocessing/","text":"indoNLP.preprocessing indoNLP.preprocessing adalah modul yang bertujuan untuk memudahkan proses preprocessing data teks dengan menggunakan beberapa fungsi yang siap digunakan. emoji_to_words ( text , lang = 'id' , use_alias = False , delimiter = ( '!' , '!' )) Transformasi emoji yang ada di dalam teks menjadi kata - kata yang sesuai dengan emoji tersebut dalam Bahasa Indonesia. Parameters: Name Type Description Default text str Teks yang terdapat emoji di dalamnya. required lang str Kode bahasa, bahasa yang tersedia yaitu \"en\" (English) dan \"id\" (Bahasa Indonesia). 'id' use_alias bool Menggunakan alias translation, alias adalah terjemahan yang lebih spesifik terhadap emoji tersebut. Tidak setiap emoji memiliki alias dan use_alias hanya didukung untuk Bahasa Indonesia lang=\"id\" . False delimiter Tuple [ str , str ] Delimiter (pembatas) pada terjemahan emoji, berupa tupple dengan dua element string sebagai pembatas awal dan akhir. ('!', '!') Warning Jika use_alias == True and lang != \"id\" maka akan terjadi error. Returns: Type Description str Teks yang telah di transformasi atau tidak terdapat emoji di dalamnya dan telah digantikan str dengan kata - kata yang mengekspresikan emoji tersebut. Examples: Mentransformasi emoji kedalam Bahasa Indonesia. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude00\ud83d\ude01\" ) \"emoji !wajah_gembira!!wajah_gembira_dengan_mata_bahagia!\" Mentransformasi emoji kebahasa Ingris. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude00\ud83d\ude01\" , lang = \"en\" ) \"emoji !grinning_face!!beaming_face_with_smiling_eyes!\" Menggunakan alias. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude00\" , use_alias = True ) \"emoji !wajah_gembira_bahagia_muka_senang!\" Menggunakan custom delimiter. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude01\" , delimiter = ( \"^\" , \"$\" )) \"emoji ^wajah_gembira_dengan_mata_bahagia$\" pipeline ( pipe ) Pipelining fungsi preprocessing. Parameters: Name Type Description Default pipe Sequence [ Callable [[ str ], str ]] Sequence dari fungsi - fungsi preprocessing indoNLP . required Returns: Type Description Callable [[ str ], str ] Callable pipeline. Examples: Pipelining beberapa fungsi preprocessing. >>> from indoNLP.preprocessing import pipeline , replace_word_elongation , replace_slang >>> pipe = pipeline ([ replace_word_elongation , replace_slang ]) >>> pipe ( \"Knp emg gk mw makan kenapaaa???\" ) \"kenapa memang enggak mau makan kenapa???\" remove_html ( text ) Menghapus tag - tag html yang terdapat dalam sebuah teks. Parameters: Name Type Description Default text str Teks yang memiliki html tag di dalamnya. required Returns: Type Description str Teks yang telah dibersihkan (tanpa tag - tag HTML di dalamnya). Examples: Menghapus semua tag HTML yang terdapat di dalam teks. >>> indoNLP . preprocessing . remove_html ( \"website <a href='https://google.com'>google</a>\" ) \"website google\" remove_stopwords ( text ) Menghapus stopwords yang terdapat dalam sebuah teks. Definisi Stopwords adalah kata umum ( common words ) yang biasanya muncul dalam jumlah besar dan dianggap tidak memiliki makna. Cite List stopwords Bahasa Indonesia yang digunakan diperoleh dari stopwords.net Parameters: Name Type Description Default text str Teks yang terdapat stopwords di dalamnya. required Returns: Type Description str Teks yang telah dibersihkan (tanpa stopwords di dalamnya). Examples: Menghapus semua stopwords yang terdapat di dalam sebuah teks. >>> indoNLP . preprocessing . remove_stopwords ( \"siapa yang suruh makan?!!\" ) \"suruh makan?!!\" remove_url ( text ) Menghapus URL yang terdapat dalam sebuah teks. Parameters: Name Type Description Default text str Teks yang terdapat URL di dalamnya. required Returns: Type Description str Teks yang telah dibersihkan (tanpa URL di dalamnya). Examples: Menghapus semua URL yang ada di dalam teks. >>> indoNLP . preprocessing . remove_url ( \"retrieved from https://gist.github.com/gruber/8891611\" ) \"retrieved from\" replace_slang ( text ) Menghapus slang words (kata gaul) yang terdapat dalam sebuah teks. Kata gaul dapat juga berupa singkatan yang sering digunakan dalam kehidupan sehari - hari seperti: \"yg\" -> \"yang\" \"mkn\" -> \"makan\" Cite Mapper untuk slang words yang digunakan didapatkan dari Kamus Alay - Colloquial Indonesian Lexicon oleh Salsabila, Ali, Yosef, dan Ade. Parameters: Name Type Description Default text str Teks yang terdapat slang words di dalamnya. required Returns: Type Description str Teks yang telah dimodifikasi (tanpa slang words di dalamnya). Examples: Mengganti setiap slang words yang ada di dalam teks menjadi bentuk yang lebih formal. >>> indoNLP . preprocessing . replace_slang ( \"emg siapa yg nanya?\" ) \"memang siapa yang bertanya?\" replace_word_elongation ( text ) Mengganti word elongation yang terdapat pada sebuah teks. Definisi Word elongation adalah tindakan menambahkan huruf tambahan ke kata, biasanya terdapat di akhir kata, hal ini biasanya dilakukan agar terdengar lebih ceria, ramah, dan imut. Parameters: Name Type Description Default text str Teks yang terdapat word elongation di dalamnya. required Returns: Type Description str Teks yang telah ditransformasi (tanpa word elongation ). Examples: Mengganti setiap word elongation yang terdapat pada sebuah teks. >>> indoNLP . preprocessing . replace_word_elongation ( \"kenapaaa?\" ) \"kenapa?\" words_to_emoji ( text , lang = 'id' , use_alias = False , delimiter = ( '!' , '!' )) Transformasi kata - kata dengan kode emoji menjadi emoji. Parameters: Name Type Description Default text str Teks yang terdapat kata - kata dengan kode emoji di dalamnya. required lang str Kode bahasa, bahasa yang tersedia yaitu \"en\" (English) dan \"id\" (Bahasa Indonesia). 'id' use_alias bool Menggunakan alias translation, alias adalah terjemahan yang lebih spesifik terhadap emoji tersebut. Tidak setiap emoji memiliki alias dan use_alias hanya didukung untuk Bahasa Indonesia lang=\"id\" . False delimiter Tuple [ str , str ] Delimiter (pembatas) pada kata - kata kode emoji, berupa tupple dengan dua element string sebagai pembatas awal dan akhir. ('!', '!') Returns: Type Description str Teks yang telah di transformasi atau kata - kata yang mengandung kode emoji di dalam teks str telah diubah menjadi emooji. Examples: Transformasi kata - kata kode emoji di dalam teks menjadi emoji. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji !wajah_gembira!!wajah_gembira_dengan_mata_bahagia!\" ) \"emoji \ud83d\ude00\ud83d\ude01\" Transform english words to emoji >>> indoNLP . preprocessing . emoji_to_words ( \"emoji !beaming_face_with_smiling_eyes!\" , lang = \"en\" ) \"emoji \ud83d\ude01\" Using alias. Only works on lang == \"id\" >>> indoNLP . preprocessing . emoji_to_words ( \"emoji !wajah_gembira_bahagia_muka_senang!\" , use_alias = True ) \"emoji \ud83d\ude00\" Using custom delimiter >>> indoNLP . preprocessing . emoji_to_words ( \"emoji ^wajah_gembira_dengan_mata_bahagia$\" , delimiter = ( \"^\" , \"$\" )) \"emoji \ud83d\ude01\"","title":"Preprocessing"},{"location":"api/preprocessing/#indonlppreprocessing","text":"indoNLP.preprocessing adalah modul yang bertujuan untuk memudahkan proses preprocessing data teks dengan menggunakan beberapa fungsi yang siap digunakan.","title":"indoNLP.preprocessing"},{"location":"api/preprocessing/#indoNLP.preprocessing.emoji_to_words","text":"Transformasi emoji yang ada di dalam teks menjadi kata - kata yang sesuai dengan emoji tersebut dalam Bahasa Indonesia. Parameters: Name Type Description Default text str Teks yang terdapat emoji di dalamnya. required lang str Kode bahasa, bahasa yang tersedia yaitu \"en\" (English) dan \"id\" (Bahasa Indonesia). 'id' use_alias bool Menggunakan alias translation, alias adalah terjemahan yang lebih spesifik terhadap emoji tersebut. Tidak setiap emoji memiliki alias dan use_alias hanya didukung untuk Bahasa Indonesia lang=\"id\" . False delimiter Tuple [ str , str ] Delimiter (pembatas) pada terjemahan emoji, berupa tupple dengan dua element string sebagai pembatas awal dan akhir. ('!', '!') Warning Jika use_alias == True and lang != \"id\" maka akan terjadi error. Returns: Type Description str Teks yang telah di transformasi atau tidak terdapat emoji di dalamnya dan telah digantikan str dengan kata - kata yang mengekspresikan emoji tersebut. Examples: Mentransformasi emoji kedalam Bahasa Indonesia. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude00\ud83d\ude01\" ) \"emoji !wajah_gembira!!wajah_gembira_dengan_mata_bahagia!\" Mentransformasi emoji kebahasa Ingris. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude00\ud83d\ude01\" , lang = \"en\" ) \"emoji !grinning_face!!beaming_face_with_smiling_eyes!\" Menggunakan alias. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude00\" , use_alias = True ) \"emoji !wajah_gembira_bahagia_muka_senang!\" Menggunakan custom delimiter. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji \ud83d\ude01\" , delimiter = ( \"^\" , \"$\" )) \"emoji ^wajah_gembira_dengan_mata_bahagia$\"","title":"emoji_to_words()"},{"location":"api/preprocessing/#indoNLP.preprocessing.pipeline","text":"Pipelining fungsi preprocessing. Parameters: Name Type Description Default pipe Sequence [ Callable [[ str ], str ]] Sequence dari fungsi - fungsi preprocessing indoNLP . required Returns: Type Description Callable [[ str ], str ] Callable pipeline. Examples: Pipelining beberapa fungsi preprocessing. >>> from indoNLP.preprocessing import pipeline , replace_word_elongation , replace_slang >>> pipe = pipeline ([ replace_word_elongation , replace_slang ]) >>> pipe ( \"Knp emg gk mw makan kenapaaa???\" ) \"kenapa memang enggak mau makan kenapa???\"","title":"pipeline()"},{"location":"api/preprocessing/#indoNLP.preprocessing.remove_html","text":"Menghapus tag - tag html yang terdapat dalam sebuah teks. Parameters: Name Type Description Default text str Teks yang memiliki html tag di dalamnya. required Returns: Type Description str Teks yang telah dibersihkan (tanpa tag - tag HTML di dalamnya). Examples: Menghapus semua tag HTML yang terdapat di dalam teks. >>> indoNLP . preprocessing . remove_html ( \"website <a href='https://google.com'>google</a>\" ) \"website google\"","title":"remove_html()"},{"location":"api/preprocessing/#indoNLP.preprocessing.remove_stopwords","text":"Menghapus stopwords yang terdapat dalam sebuah teks. Definisi Stopwords adalah kata umum ( common words ) yang biasanya muncul dalam jumlah besar dan dianggap tidak memiliki makna. Cite List stopwords Bahasa Indonesia yang digunakan diperoleh dari stopwords.net Parameters: Name Type Description Default text str Teks yang terdapat stopwords di dalamnya. required Returns: Type Description str Teks yang telah dibersihkan (tanpa stopwords di dalamnya). Examples: Menghapus semua stopwords yang terdapat di dalam sebuah teks. >>> indoNLP . preprocessing . remove_stopwords ( \"siapa yang suruh makan?!!\" ) \"suruh makan?!!\"","title":"remove_stopwords()"},{"location":"api/preprocessing/#indoNLP.preprocessing.remove_url","text":"Menghapus URL yang terdapat dalam sebuah teks. Parameters: Name Type Description Default text str Teks yang terdapat URL di dalamnya. required Returns: Type Description str Teks yang telah dibersihkan (tanpa URL di dalamnya). Examples: Menghapus semua URL yang ada di dalam teks. >>> indoNLP . preprocessing . remove_url ( \"retrieved from https://gist.github.com/gruber/8891611\" ) \"retrieved from\"","title":"remove_url()"},{"location":"api/preprocessing/#indoNLP.preprocessing.replace_slang","text":"Menghapus slang words (kata gaul) yang terdapat dalam sebuah teks. Kata gaul dapat juga berupa singkatan yang sering digunakan dalam kehidupan sehari - hari seperti: \"yg\" -> \"yang\" \"mkn\" -> \"makan\" Cite Mapper untuk slang words yang digunakan didapatkan dari Kamus Alay - Colloquial Indonesian Lexicon oleh Salsabila, Ali, Yosef, dan Ade. Parameters: Name Type Description Default text str Teks yang terdapat slang words di dalamnya. required Returns: Type Description str Teks yang telah dimodifikasi (tanpa slang words di dalamnya). Examples: Mengganti setiap slang words yang ada di dalam teks menjadi bentuk yang lebih formal. >>> indoNLP . preprocessing . replace_slang ( \"emg siapa yg nanya?\" ) \"memang siapa yang bertanya?\"","title":"replace_slang()"},{"location":"api/preprocessing/#indoNLP.preprocessing.replace_word_elongation","text":"Mengganti word elongation yang terdapat pada sebuah teks. Definisi Word elongation adalah tindakan menambahkan huruf tambahan ke kata, biasanya terdapat di akhir kata, hal ini biasanya dilakukan agar terdengar lebih ceria, ramah, dan imut. Parameters: Name Type Description Default text str Teks yang terdapat word elongation di dalamnya. required Returns: Type Description str Teks yang telah ditransformasi (tanpa word elongation ). Examples: Mengganti setiap word elongation yang terdapat pada sebuah teks. >>> indoNLP . preprocessing . replace_word_elongation ( \"kenapaaa?\" ) \"kenapa?\"","title":"replace_word_elongation()"},{"location":"api/preprocessing/#indoNLP.preprocessing.words_to_emoji","text":"Transformasi kata - kata dengan kode emoji menjadi emoji. Parameters: Name Type Description Default text str Teks yang terdapat kata - kata dengan kode emoji di dalamnya. required lang str Kode bahasa, bahasa yang tersedia yaitu \"en\" (English) dan \"id\" (Bahasa Indonesia). 'id' use_alias bool Menggunakan alias translation, alias adalah terjemahan yang lebih spesifik terhadap emoji tersebut. Tidak setiap emoji memiliki alias dan use_alias hanya didukung untuk Bahasa Indonesia lang=\"id\" . False delimiter Tuple [ str , str ] Delimiter (pembatas) pada kata - kata kode emoji, berupa tupple dengan dua element string sebagai pembatas awal dan akhir. ('!', '!') Returns: Type Description str Teks yang telah di transformasi atau kata - kata yang mengandung kode emoji di dalam teks str telah diubah menjadi emooji. Examples: Transformasi kata - kata kode emoji di dalam teks menjadi emoji. >>> indoNLP . preprocessing . emoji_to_words ( \"emoji !wajah_gembira!!wajah_gembira_dengan_mata_bahagia!\" ) \"emoji \ud83d\ude00\ud83d\ude01\" Transform english words to emoji >>> indoNLP . preprocessing . emoji_to_words ( \"emoji !beaming_face_with_smiling_eyes!\" , lang = \"en\" ) \"emoji \ud83d\ude01\" Using alias. Only works on lang == \"id\" >>> indoNLP . preprocessing . emoji_to_words ( \"emoji !wajah_gembira_bahagia_muka_senang!\" , use_alias = True ) \"emoji \ud83d\ude00\" Using custom delimiter >>> indoNLP . preprocessing . emoji_to_words ( \"emoji ^wajah_gembira_dengan_mata_bahagia$\" , delimiter = ( \"^\" , \"$\" )) \"emoji \ud83d\ude01\"","title":"words_to_emoji()"},{"location":"development/","text":"Development Untuk development indoNLP menggunakan python-poetry untuk packaging dan management dependencies. Install python-poetry Silahkan kunjungi installation untuk melihat cara installasi dari python-poetry berdasarkan OS yang digunakan. Setup Setup development environment, dengan menggunakan command $ make setup-dev Command tersebut akan menginstall semua dependencies yang digunakan oleh indoNLP dalam tahap development. Make Commands Commands yang terdapat pada Makefile digunakan untuk memudahkan proses development yaitu: setup-dev digunakan untuk setup development environment. format digunakan untuk mengformat menggunakan black dan isort . format-check digunakan untuk melihat apakah project telah mengikuti ketentuan black dan isort . typecheck digunakan untuk type checking menggunakan mypy test digunakan untuk melakukan testing menggunakan pytest Coverage Target Code coverage yang ditargetkan pada indoNLP adalah lebih dari 95%. pre-commit Sebelum melakukan commit pastikan kode lolos format-check dan typecheck karena akan diujikan oleh pre-commit , jika tidak lolos maka commit akan ditolak. Perhatian Pastikan anda berada dalam environment poetry saat melakukan commit , cara mengaktifkannya adalah dengan menggunakan command poetry shell","title":"Development"},{"location":"development/#development","text":"Untuk development indoNLP menggunakan python-poetry untuk packaging dan management dependencies. Install python-poetry Silahkan kunjungi installation untuk melihat cara installasi dari python-poetry berdasarkan OS yang digunakan.","title":"Development"},{"location":"development/#setup","text":"Setup development environment, dengan menggunakan command $ make setup-dev Command tersebut akan menginstall semua dependencies yang digunakan oleh indoNLP dalam tahap development.","title":"Setup"},{"location":"development/#make-commands","text":"Commands yang terdapat pada Makefile digunakan untuk memudahkan proses development yaitu: setup-dev digunakan untuk setup development environment. format digunakan untuk mengformat menggunakan black dan isort . format-check digunakan untuk melihat apakah project telah mengikuti ketentuan black dan isort . typecheck digunakan untuk type checking menggunakan mypy test digunakan untuk melakukan testing menggunakan pytest","title":"Make Commands"},{"location":"development/#coverage-target","text":"Code coverage yang ditargetkan pada indoNLP adalah lebih dari 95%.","title":"Coverage Target"},{"location":"development/#pre-commit","text":"Sebelum melakukan commit pastikan kode lolos format-check dan typecheck karena akan diujikan oleh pre-commit , jika tidak lolos maka commit akan ditolak. Perhatian Pastikan anda berada dalam environment poetry saat melakukan commit , cara mengaktifkannya adalah dengan menggunakan command poetry shell","title":"pre-commit"},{"location":"development/new-sup-dataset/","text":"Request Penambahan Supported Dataset Menambahkan Dataset Tambahkan informasi terkait dataset pada file indoNLP/dataset/list.py dengan ketentuan sebagai berikut: ... , \"{{ ID-DATASET-BARU }}\" : { \"info\" : { \"description\" : str , # Deskripsi singkat tentang dataset \"author\" : str , # Orang - orang yang memiliki hak cipta terhadap dataset \"year\" : int , # Tahun dataset dipublish \"citation\" : str , # Cara mengutip dataset \"homepage\" : str , # Website atau halaman utama dataset \"tags\" : List [ str ], # Tag - tag yang berhubungan dengan dataset }, \"files\" : [ # Berisi file - file yang terdapat dalam dataset { \"filename\" : str , # Nama file \"url\" : str , # URL atau endpoint tempat file dapat didownload \"is_large\" : bool , # Apakah ukuran file besar? \"extract\" : bool , # Apakah file perlu dilakukan ekstraksi? }, ... ], \"reader\" : { # Berisi keterangan tentang semua file yang terdapat di dataset \"{{ ID-FILE }}\" : { # id file dalam dataset agar dapat dikenali oleh method .read \"path\" : str , # path ke file yang akan dibaca relative terhadap `downloader.dataset_dir` \"is_table\" : bool , # Apakah data dalam file bersifat simetrik? \"reader\" : Callable , # Fungsi yang digunakan untuk membaca data pada file terdapat # pada indoNLP/dataset/reader.py jika tidak terdapat fungsi yang # tersedia maka buat fungsi baru dengan format yang sama terhadap # fungsi reader yang lain [TANPA TAMBAHAN DEPENDENCIES]. \"args\" : Dict , # kwargs yang perlu dipass kefungsi reader. }, ... }, }, } Ketentuan Jika diperlukan untuk menambah fungsi reader baru pastikan untuk menambakan juga test case pada file tests/dataset/test_reader.py untuk unit testing dan juga memperhatikan ketentuan code coverage . Warning Dalam pembuatan fungsi reader baru utamakan tidak menggunakan dependensi tambahan selain python standard library . Membuat Pull Request Setelah semua ketentuan tercapai buat Pull Request di repository indoNLP , akan dilakukan review apakah dataset dapat ditambahkan atau tidak.","title":"Penambahan Supported Dataset"},{"location":"development/new-sup-dataset/#request-penambahan-supported-dataset","text":"","title":"Request Penambahan Supported Dataset"},{"location":"development/new-sup-dataset/#menambahkan-dataset","text":"Tambahkan informasi terkait dataset pada file indoNLP/dataset/list.py dengan ketentuan sebagai berikut: ... , \"{{ ID-DATASET-BARU }}\" : { \"info\" : { \"description\" : str , # Deskripsi singkat tentang dataset \"author\" : str , # Orang - orang yang memiliki hak cipta terhadap dataset \"year\" : int , # Tahun dataset dipublish \"citation\" : str , # Cara mengutip dataset \"homepage\" : str , # Website atau halaman utama dataset \"tags\" : List [ str ], # Tag - tag yang berhubungan dengan dataset }, \"files\" : [ # Berisi file - file yang terdapat dalam dataset { \"filename\" : str , # Nama file \"url\" : str , # URL atau endpoint tempat file dapat didownload \"is_large\" : bool , # Apakah ukuran file besar? \"extract\" : bool , # Apakah file perlu dilakukan ekstraksi? }, ... ], \"reader\" : { # Berisi keterangan tentang semua file yang terdapat di dataset \"{{ ID-FILE }}\" : { # id file dalam dataset agar dapat dikenali oleh method .read \"path\" : str , # path ke file yang akan dibaca relative terhadap `downloader.dataset_dir` \"is_table\" : bool , # Apakah data dalam file bersifat simetrik? \"reader\" : Callable , # Fungsi yang digunakan untuk membaca data pada file terdapat # pada indoNLP/dataset/reader.py jika tidak terdapat fungsi yang # tersedia maka buat fungsi baru dengan format yang sama terhadap # fungsi reader yang lain [TANPA TAMBAHAN DEPENDENCIES]. \"args\" : Dict , # kwargs yang perlu dipass kefungsi reader. }, ... }, }, }","title":"Menambahkan Dataset"},{"location":"development/new-sup-dataset/#ketentuan","text":"Jika diperlukan untuk menambah fungsi reader baru pastikan untuk menambakan juga test case pada file tests/dataset/test_reader.py untuk unit testing dan juga memperhatikan ketentuan code coverage . Warning Dalam pembuatan fungsi reader baru utamakan tidak menggunakan dependensi tambahan selain python standard library .","title":"Ketentuan"},{"location":"development/new-sup-dataset/#membuat-pull-request","text":"Setelah semua ketentuan tercapai buat Pull Request di repository indoNLP , akan dilakukan review apakah dataset dapat ditambahkan atau tidak.","title":"Membuat Pull Request"}]}